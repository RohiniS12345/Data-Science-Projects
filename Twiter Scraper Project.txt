!pip install snscrape
!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git
!pip install pymongo
import streamlit as st
import snscrape.modules.twitter as sntwitter
import pandas as pd
import snscrape.modules.twitter as sntwitter
maxTweets = 10
keyword='tb2'
for i, tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + ' since:2021-11-01 until:2023-01-01 lang:"en" ').get_items()):
    tweets = {
            "Tweet" : "Reply",
            "tweet/reply id": "a"+str(tweet.id),
            "inReplyToTweetId": "a"+str(tweet.inReplyToTweetId),
            "conversationId": "a"+str(tweet.conversationId),
            "tweet.username" : tweet.username,
            "tweet.content" : tweet.content,
            "tweet.date" : tweet.date,
            "tweet.user.location" : tweet.user.location,
            "tweet.likeCount" : tweet.likeCount, 
            "tweet.replyCount" : tweet.replyCount,
            "tweet.retweetCount" : tweet.retweetCount,
            "tweet.user.followersCount" : tweet.user.followersCount,
            "tweet.user.description": tweet.user.description,
            "tweet.user.friendsCount": tweet.user.friendsCount,
            "tweet.user.statusesCount": tweet.user.statusesCount,
            "tweet.user.favouritesCount": tweet.user.favouritesCount,
            "tweet.user.listedCount": tweet.user.listedCount,
            "tweet.user.mediaCount": tweet.user.mediaCount,
            "tweet.url" : tweet.url
            }   
    print(tweets) 
tweets_df.head(100)
# Created a list to append all tweet attributes(data)
attributes_container = []

# Using TwitterSearchScraper to scrape data and append tweets to list
for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:john').get_items()):
    if i>100:
        break
    attributes_container.append([tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content])
    
# Creating a dataframe from the tweets list above 
tweets_df = pd.DataFrame(attributes_container, columns=["Date Created", "Number of Likes", "Source of Tweet", "Tweets"])
for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:john').get_items()):
    if i>100:
        break
    attributes_container.append([tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content])
    
    tweets_df.head(100)
